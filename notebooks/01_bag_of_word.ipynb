{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-11-23T17:34:47.939460Z","iopub.status.busy":"2021-11-23T17:34:47.938830Z","iopub.status.idle":"2021-11-23T17:34:47.943957Z","shell.execute_reply":"2021-11-23T17:34:47.943323Z","shell.execute_reply.started":"2021-11-23T17:34:47.939411Z"},"trusted":true},"outputs":[],"source":["import os \n","\n","is_kaggle = False\n","if os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None:\n","    is_kaggle = True"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-23T17:37:56.583688Z","iopub.status.busy":"2021-11-23T17:37:56.583252Z","iopub.status.idle":"2021-11-23T17:38:09.173015Z","shell.execute_reply":"2021-11-23T17:38:09.171691Z","shell.execute_reply.started":"2021-11-23T17:37:56.583649Z"},"trusted":true},"outputs":[],"source":["%%capture\n","if is_kaggle:\n","    !pip install ../input/sklearn-1-0/scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["from pathlib import Path\n","from typing import Tuple, List\n","\n","import pandas as pd\n","import joblib\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["seed = 32"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["is_kaggle = False\n","if os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None:\n","    is_kaggle = True"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["data_path = Path(\"..\") / \"data\" / \"raw\"\n","output_path = Path(\"..\") / 'data' / \"submissions\"\n","output_file_name = 'lg.csv'\n","if is_kaggle:\n","    data_path = Path('/kaggle') / 'input' / 'jigsaw-unintended-bias-in-toxicity-classification'\n","    output_path = Path(\"/kaggle\") / \"working\"\n","    output_file_name = 'submission.csv'"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["PosixPath('../data/raw')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data_path"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["identity_columns = [\n","    \"male\",\n","    \"female\",\n","    \"homosexual_gay_or_lesbian\",\n","    \"christian\",\n","    \"jewish\",\n","    \"muslim\",\n","    \"black\",\n","    \"white\",\n","    \"psychiatric_or_mental_illness\",\n","]"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(data_path / 'train.csv')"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","      <th>comment_text</th>\n","      <th>severe_toxicity</th>\n","      <th>obscene</th>\n","      <th>identity_attack</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>...</th>\n","      <th>article_id</th>\n","      <th>rating</th>\n","      <th>funny</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>59848</td>\n","      <td>0.0</td>\n","      <td>This is so cool. It's like, 'would you want yo...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>59849</td>\n","      <td>0.0</td>\n","      <td>Thank you!! This would make my life a lot less...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows Ã— 45 columns</p>\n","</div>"],"text/plain":["      id  target                                       comment_text  \\\n","0  59848     0.0  This is so cool. It's like, 'would you want yo...   \n","1  59849     0.0  Thank you!! This would make my life a lot less...   \n","\n","   severe_toxicity  obscene  identity_attack  insult  threat  asian  atheist  \\\n","0              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n","1              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n","\n","   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n","0  ...        2006  rejected      0    0    0      0         0   \n","1  ...        2006  rejected      0    0    0      0         0   \n","\n","   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n","0              0.0                         0                         4  \n","1              0.0                         0                         4  \n","\n","[2 rows x 45 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.head(2)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["df['label'] = (df['target'] >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["x = df['comment_text']\n","y = df['label']"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def convert_dataframe_to_bool(\n","    df: pd.DataFrame, identity_columns: List[str] = identity_columns\n",") -> pd.DataFrame:\n","    \"\"\"Convert identity columns to boolen columns\"\"\"\n","    bool_df = df.copy()\n","    for col in identity_columns:\n","        bool_df[col] = np.where(df[col] >= 0.5, True, False)\n","    return bool_df\n","\n","\n","df = convert_dataframe_to_bool(df)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["def get_x_y(df: pd.DataFrame, input_col='comment_text', label_col='label') -> Tuple[pd.DataFrame, pd.DataFrame]:\n","    return df[input_col], df[label_col]"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["df_train, df_valid = train_test_split(df, test_size=0.2, random_state=seed)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["x_train, y_train= get_x_y(df_train)\n","x_valid, y_valid = get_x_y(df_valid)"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess Data"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["train_text = list(x_train.values)\n","valid_text = list(x_valid.values)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["vectorizer = CountVectorizer(\n","    stop_words=\"english\", max_features=5000, min_df=0.001, max_df=0.99\n",")\n","x_train_prepared = vectorizer.fit_transform(train_text)\n","x_valid_prepared = vectorizer.transform(valid_text)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["((1443899, 3691), (360975, 3691))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["x_train_prepared.shape, x_valid_prepared.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array(['00', '000', '01', ..., 'zero', 'zone', 'zuma'], dtype=object)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer.get_feature_names_out()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["['../models/bow/vectorizer.joblib']"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["joblib.dump(vectorizer, \"../models/bow/vectorizer.joblib\")"]},{"cell_type":"markdown","metadata":{},"source":["## Train Model"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["mod_lg = LogisticRegression(random_state=seed, solver='liblinear')"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["_ = mod_lg.fit(x_train_prepared, y_train)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["['../models/bow/logistic.joblib']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["joblib.dump(mod_lg, \"../models/bow/logistic.joblib\")"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Model"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def compute_auc(y_true, y_pred):\n","    try:\n","        return metrics.roc_auc_score(y_true, y_pred)\n","    except ValueError:\n","        return np.nan\n","\n","\n","def compute_subgroup_auc(\n","    df: pd.DataFrame, subgroup: str, label_col: str, y_proba_col: str\n",") -> float:\n","    subgroup_examples = df[df[subgroup]]\n","    return compute_auc(subgroup_examples[label_col], subgroup_examples[y_proba_col])\n","\n","\n","def compute_bpsn_auc(df, subgroup, label, y_proba_col):\n","    \"\"\"\n","    Computes the AUC of the within-subgroup negative examples\n","    and the background positive examples.\n","    \"\"\"\n","    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n","    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n","    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n","    return compute_auc(examples[label], examples[y_proba_col])\n","\n","\n","def compute_bnsp_auc(df, subgroup, label, y_proba_col):\n","    \"\"\"\n","    Computes the AUC of the within-subgroup positive examples and the\n","    background negative examples.\n","    \"\"\"\n","    subgroup_positive_examples = df[df[subgroup] & df[label]]\n","    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n","    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n","    return compute_auc(examples[label], examples[y_proba_col])\n","\n","\n","def compute_bias_metrics_for_model(\n","    dataset: pd.DataFrame, subgroups: List[str], y_proba_col: str, label_col: str\n","):\n","    \"\"\"Computes per-subgroup metrics for all subgroups\"\"\"\n","    records = []\n","    for subgroup in subgroups:\n","        record = {\n","            \"subgroup\": subgroup,\n","            \"subgroup_size\": len(dataset[dataset[subgroup]]),\n","        }\n","        record[\"subgroup_auc\"] = compute_subgroup_auc(\n","            dataset, subgroup, label_col, y_proba_col\n","        )\n","        # background positive, subgroup negative\n","        record[\"bpsn_auc\"] = compute_bpsn_auc(dataset, subgroup, label_col, y_proba_col)\n","        # background negative, subgroup positive\n","        record[\"bnsp_auc\"] = compute_bnsp_auc(dataset, subgroup, label_col, y_proba_col)\n","        records.append(record)\n","    return pd.DataFrame(records).sort_values(\"subgroup_auc\", ascending=True)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["def get_freq_table(df: pd.DataFrame, col: str) -> pd.DataFrame:\n","    \"\"\"Get the count and percentage of each unique value in the column\"\"\"\n","    num_count = df[col].value_counts()\n","    perc_count = df[col].value_counts(normalize=True)\n","    df_sum = pd.concat([num_count, perc_count], axis=1)\n","    df_sum.columns = [\"count\", \"percentage\"]\n","    return df_sum"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate_model(df: pd.DataFrame, label_col: str = \"label\") -> pd.DataFrame:\n","    y_true = df[label_col].values\n","    y_pred = df[\"y_pred\"].values\n","    y_proba = df[\"y_pred_proba\"].values\n","\n","    acc = metrics.accuracy_score(y_true, y_pred)\n","    f1 = metrics.f1_score(y_true, y_pred)\n","    auc_roc = metrics.roc_auc_score(y_true, y_proba)\n","\n","    df_result = pd.DataFrame(\n","        {\"metrics\": [\"accuracy\", \"f1\", \"auc_roc\"], \"value\": [acc, f1, auc_roc]}\n","    )\n","    return df_result\n"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["df_eval = df_valid.reset_index(drop=True).copy()"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["df_eval['y_pred'] = mod_lg.predict(x_valid_prepared)\n","df_eval['y_pred_proba'] = mod_lg.predict_proba(x_valid_prepared)[:, 1]"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","      <th>comment_text</th>\n","      <th>severe_toxicity</th>\n","      <th>obscene</th>\n","      <th>identity_attack</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>...</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","      <th>label</th>\n","      <th>y_pred</th>\n","      <th>y_pred_proba</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>310214</td>\n","      <td>0.0</td>\n","      <td>I am not suggesting that the sate run an oil c...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.005680</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>344184</td>\n","      <td>0.0</td>\n","      <td>Aloha Luke, another great column.  We have bee...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.002334</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows Ã— 48 columns</p>\n","</div>"],"text/plain":["       id  target                                       comment_text  \\\n","0  310214     0.0  I am not suggesting that the sate run an oil c...   \n","1  344184     0.0  Aloha Luke, another great column.  We have bee...   \n","\n","   severe_toxicity  obscene  identity_attack  insult  threat  asian  atheist  \\\n","0              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n","1              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n","\n","   ...  wow  sad  likes  disagree  sexual_explicit  identity_annotator_count  \\\n","0  ...    0    0      0         0              0.0                         0   \n","1  ...    0    0      1         0              0.0                         0   \n","\n","   toxicity_annotator_count  label  y_pred  y_pred_proba  \n","0                         4      0       0      0.005680  \n","1                         4      0       0      0.002334  \n","\n","[2 rows x 48 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df_eval.head(2)"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>332132</td>\n","      <td>0.920097</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28843</td>\n","      <td>0.079903</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    count  percentage\n","0  332132    0.920097\n","1   28843    0.079903"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["get_freq_table(df_valid, col='label')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subgroup</th>\n","      <th>subgroup_size</th>\n","      <th>subgroup_auc</th>\n","      <th>bpsn_auc</th>\n","      <th>bnsp_auc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>homosexual_gay_or_lesbian</td>\n","      <td>2208</td>\n","      <td>0.748368</td>\n","      <td>0.763592</td>\n","      <td>0.876749</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>black</td>\n","      <td>3107</td>\n","      <td>0.752519</td>\n","      <td>0.708626</td>\n","      <td>0.921839</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>white</td>\n","      <td>5016</td>\n","      <td>0.775468</td>\n","      <td>0.717442</td>\n","      <td>0.929837</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>muslim</td>\n","      <td>4206</td>\n","      <td>0.784206</td>\n","      <td>0.750862</td>\n","      <td>0.921171</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>jewish</td>\n","      <td>1513</td>\n","      <td>0.806274</td>\n","      <td>0.803642</td>\n","      <td>0.888003</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>psychiatric_or_mental_illness</td>\n","      <td>991</td>\n","      <td>0.816129</td>\n","      <td>0.780970</td>\n","      <td>0.923800</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>male</td>\n","      <td>8926</td>\n","      <td>0.838875</td>\n","      <td>0.820773</td>\n","      <td>0.896875</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>10774</td>\n","      <td>0.841832</td>\n","      <td>0.837805</td>\n","      <td>0.886515</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>christian</td>\n","      <td>8341</td>\n","      <td>0.862200</td>\n","      <td>0.885028</td>\n","      <td>0.857405</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n","2      homosexual_gay_or_lesbian           2208      0.748368  0.763592   \n","6                          black           3107      0.752519  0.708626   \n","7                          white           5016      0.775468  0.717442   \n","5                         muslim           4206      0.784206  0.750862   \n","4                         jewish           1513      0.806274  0.803642   \n","8  psychiatric_or_mental_illness            991      0.816129  0.780970   \n","0                           male           8926      0.838875  0.820773   \n","1                         female          10774      0.841832  0.837805   \n","3                      christian           8341      0.862200  0.885028   \n","\n","   bnsp_auc  \n","2  0.876749  \n","6  0.921839  \n","7  0.929837  \n","5  0.921171  \n","4  0.888003  \n","8  0.923800  \n","0  0.896875  \n","1  0.886515  \n","3  0.857405  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["bias_metrics_df = compute_bias_metrics_for_model(df_eval, identity_columns, 'y_pred_proba', 'label')\n","bias_metrics_df"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>metrics</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>accuracy</td>\n","      <td>0.939295</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>f1</td>\n","      <td>0.491920</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>auc_roc</td>\n","      <td>0.881184</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    metrics     value\n","0  accuracy  0.939295\n","1        f1  0.491920\n","2   auc_roc  0.881184"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["evaluate_model(df_eval)"]},{"cell_type":"markdown","metadata":{},"source":["## Explain Model"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>coef</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>knee</td>\n","      <td>-1.296578</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>april</td>\n","      <td>-0.765470</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>rare</td>\n","      <td>-0.697855</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>discussions</td>\n","      <td>-0.690627</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>steps</td>\n","      <td>-0.658778</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3686</th>\n","      <td>moron</td>\n","      <td>4.526702</td>\n","    </tr>\n","    <tr>\n","      <th>3687</th>\n","      <td>stupid</td>\n","      <td>4.832190</td>\n","    </tr>\n","    <tr>\n","      <th>3688</th>\n","      <td>stupidity</td>\n","      <td>4.934228</td>\n","    </tr>\n","    <tr>\n","      <th>3689</th>\n","      <td>idiots</td>\n","      <td>5.461493</td>\n","    </tr>\n","    <tr>\n","      <th>3690</th>\n","      <td>idiot</td>\n","      <td>5.530527</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3691 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["             name      coef\n","0            knee -1.296578\n","1           april -0.765470\n","2            rare -0.697855\n","3     discussions -0.690627\n","4           steps -0.658778\n","...           ...       ...\n","3686        moron  4.526702\n","3687       stupid  4.832190\n","3688    stupidity  4.934228\n","3689       idiots  5.461493\n","3690        idiot  5.530527\n","\n","[3691 rows x 2 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_coef = pd.DataFrame({\"name\": vectorizer.get_feature_names_out(), \"coef\": mod_lg.coef_[0]})\n","df_coef.sort_values('coef', ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Make Submission"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[],"source":["df_test = pd.read_csv(data_path / 'test.csv')"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7097320</td>\n","      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7097321</td>\n","      <td>This is malfeasance by the Administrator and t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                       comment_text\n","0  7097320  [ Integrity means that you pay your debts.]\\n\\...\n","1  7097321  This is malfeasance by the Administrator and t..."]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head(2)"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["x_test_prepared = vectorizer.transform(list(df_test.comment_text.values))"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["prediction = mod_lg.predict_proba(x_test_prepared)[:, 1]"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array([0.05108628, 0.06198041, 0.03860329, ..., 0.05951157, 0.16083905,\n","       0.00889832])"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["prediction"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[],"source":["df_submit = pd.DataFrame({'id': df_test.id.values, 'prediction': prediction})\n","df_submit.to_csv(output_path / output_file_name, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Calculate Submission Metrics"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def calculate_overall_auc(df, model_name):\n","    true_labels = df[\"label\"]\n","    predicted_labels = df[model_name]\n","    return metrics.roc_auc_score(true_labels, predicted_labels)\n","\n","\n","def power_mean(series, p):\n","    total = sum(np.power(series, p))\n","    return np.power(total / len(series), 1 / p)\n","\n","\n","def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n","    bias_score = np.average(\n","        [\n","            power_mean(bias_df[\"subgroup_auc\"], POWER),\n","            power_mean(bias_df[\"bpsn_auc\"], POWER),\n","            power_mean(bias_df[\"bnsp_auc\"], POWER),\n","        ]\n","    )\n","    return (OVERALL_MODEL_WEIGHT * overall_auc) + (\n","        (1 - OVERALL_MODEL_WEIGHT) * bias_score\n","    )\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["df_test_complete  = pd.read_csv(data_path / 'test_private_expanded.csv')\n","df_test_complete = convert_dataframe_to_bool(df_test_complete)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["df_test_complete['y_pred_proba'] = prediction\n","df_test_complete['y_pred'] = (prediction >= 0.5).astype(int)\n","df_test_complete['label'] = (df_test_complete.toxicity >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>metrics</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>accuracy</td>\n","      <td>0.938440</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>f1</td>\n","      <td>0.483312</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>auc_roc</td>\n","      <td>0.879092</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    metrics     value\n","0  accuracy  0.938440\n","1        f1  0.483312\n","2   auc_roc  0.879092"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["evaluate_model(df_test_complete)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["bias_metrics_df = compute_bias_metrics_for_model(df_test_complete, identity_columns, 'y_pred_proba', 'label')"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["0.8322929932994851"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["get_final_metric(bias_metrics_df, calculate_overall_auc(df_test_complete, 'y_pred_proba'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
